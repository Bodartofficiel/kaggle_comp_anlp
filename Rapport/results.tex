
Pour évaluer la performance de nos modèles on utilise l'accuracy comme score car les classes sont plus ou moins équilibrés dans notre corpus.

Les resultats des différents modèles sont présentés dans le tableau \ref{tab:results}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccc}
        \toprule
        Modèle & val acc & Test acc  & inférence* \\
        \midrule
        FastText & -- & -- & -- \\
        TFIDF & 0.70 & -- & -- \\
        mBERT & 0.86 & 0.86 & 1h \\
        XLM-roBERTa & -- & -- & -- \\
        FT + XLM-R & -- & -- & -- \\
        \bottomrule
    \end{tabular}

    \caption{Accuracy sur le val et sur le test des modèles essayés. (*durée d'inférence sur un laptop classique sur tout le corpus de texte)}
    
    \label{tab:results}
\end{table}

Pour conclure, il était prédictible que l'adaptation modèles de languages neuronaux lourd donneraient des très bons résultats pour la détection de langues en contrapartie de lourrds coûts en entrainement et en inférence. Mais on a été particularièrement surpris par la performance de FastText qui a donné des résultats très proches des modèles neuronaux en un temps d'inférence quasi instantané. C'est pourquoi nous avons décidé de combiner FastText et XLM-RoBERTa pour obtenir un modèle plus performant en score et en coût d'inférence.